import pandas as pd
from datetime import datetime
from airflow.models import DAG
from airflow.operators.python import PythonOperator
from airflow.hooks.postgres_hook import PostgresHook
from airflow.models import Variable
from airflow.operators.bash import BashOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator

# 1. Get the Iris data from a table in Postgres
get_site_outage_data = PythonOperator(
    task_id='get_site_outage_data',
    python_callable=get_site_outage_data,
    do_xcom_push=True
)


def get_site_outage_data():
    sql_stmt = "SELECT * FROM logs.landing_table"
    pg_hook = PostgresHook(
        postgres_conn_id='postgres',
        schema='logs'
    )
    pg_conn = pg_hook.get_conn()
    cursor = pg_conn.cursor()
    cursor.execute(sql_stmt)
    return cursor.fetchall()


with DAG(
    dag_id='postgres_db_dag',
    schedule_interval='@daily',
    start_date=datetime(year=2022, month=2, day=1),
    catchup=False
) as dag:
    # 1. Get the Iris data from a table in Postgres
    task_get_iris_data = PythonOperator(
        task_id='get_iris_data',
        python_callable=get_iris_data,
        do_xcom_push=True
    )
